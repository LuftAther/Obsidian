
(3.7)  
$y' = A y,\quad A \in \mathbb{R}^{n \times n}$

- Fundamentalmatrix:  
  $$e^{tA} = \sum_{n=0}^{\infty} \frac{1}{n!} (tA)^n$$

- Lösung von $y' = A y,\quad y(t_0) = y_0$  
  $$y(t) = e^{(t - t_0) A} y_0$$

---

### 3.2.1 Berechnung von $e^{tA}$

$e^{tA}$ wird typischerweise durch Diagonalisieren bestimmt.  
Sei $A = V D V^{-1}$

Dann:

$$
\begin{aligned}
e^{tA} &= \sum_{n=0}^{\infty} \frac{1}{n!} (tA)^n = \sum_{n=0}^{\infty} \frac{1}{n!} (t V D V^{-1})^n \\
&= \sum_{n=0}^{\infty} \frac{1}{n!} t^n V D^n V^{-1} = V \left( \sum_{n=0}^{\infty} \frac{1}{n!} (t D)^n \right) V^{-1}
\end{aligned}
$$

Für $D = \text{diag}(d_1, \dotsc, d_n)$ gilt:

$$
e^{tD} = \sum_{n=0}^{\infty} \frac{1}{n!} t^n D^n = 
\begin{pmatrix}
e^{t d_1} & & \\
& \ddots & \\
& & e^{t d_n}
\end{pmatrix}
= \text{diag}(e^{t d_1}, \dotsc, e^{t d_n})
$$

Also:

$$
e^{tA} = V \cdot \text{diag}(e^{t d_1}, \dotsc, e^{t d_n}) \cdot V^{-1}
$$
Bem:  
Formel $e^{tA}$ kann auch als Lösung von AWP nach Basiswechsel erhalten werden:

$$
y' = A y,\quad y(0) = y_0
$$

$$
\Leftrightarrow y' = V D V^{-1} y,\quad V^{-1} y(0) = \tilde{y}_0
$$

Definiere:  
$\tilde{y} = V^{-1} y$  
$\tilde{y}(0) = \tilde{y}_0$

$$
\Leftrightarrow \tilde{y}' = D \tilde{y},\quad \tilde{y}(0) = \tilde{y}_0
$$

$$
\Leftrightarrow \tilde{y}_i' = d_i \tilde{y}_i,\quad \tilde{y}_i(0) = \tilde{y}_{0,i},\quad i = 1, \dotsc, d
$$

$$
\Leftrightarrow \tilde{y}_i(t) = e^{d_i t} \tilde{y}_{0,i}
$$

$$
\Leftrightarrow \tilde{y}(t) = 
\begin{pmatrix}
e^{d_1 t} & & \\
& \ddots & \\
& & e^{d_d t}
\end{pmatrix}
\tilde{y}_0
$$

$$
\Leftrightarrow V \tilde{y}(t) = V e^{tD} \tilde{y}_0
$$

$$
\Leftrightarrow y(t) = V e^{tD} V^{-1} y_0
$$

---

Frage:  
$e^{tA}$, falls $A$ nicht diagonalisierbar?

Antwort:  
Jordanform
Erklärung:  
Sei  
$$
B = \begin{pmatrix} B_1 & & \\ & \ddots & \\ & & B_m \end{pmatrix}
\quad \text{mit Jordanblöcken } B_i
$$

Dann:  
$$
e^{tB} = \begin{pmatrix} e^{tB_1} & & \\ & \ddots & \\ & & e^{tB_m} \end{pmatrix}
$$

Jordanform von $A$:  
$$
A = V J V^{-1}, \quad J = \begin{pmatrix} J_1 & & \\ & \ddots & \\ & & J_m \end{pmatrix}
$$

mit  
$$
J_i = \begin{pmatrix}
\lambda_i & 1 & & 0 \\
& \lambda_i & \ddots & \\
& & \ddots & 1 \\
0 & & & \lambda_i
\end{pmatrix}
$$

Daraus:  
$$
e^{tA} = V e^{tJ} V^{-1}
$$

$e^{tJ_i}$ ergibt sich nicht aus $e^{\lambda_i t}$ alleine – es entstehen zusätzliche Terme wegen der oberen Einsen in $J_i$.
## Lemma 3.16

Voraussetzung:  
Sei  
$$
J = 
\begin{pmatrix}
\lambda & 1 & & \\
& \lambda & \ddots & \\
& & \ddots & 1 \\
& & & \lambda
\end{pmatrix}
\in \mathbb{C}^{r \times r}, \quad \lambda \in \mathbb{C}
$$

Behauptung:  
Dann gilt:

$$
e^{tJ} = \sum_{n=0}^\infty \frac{1}{n!} (tJ)^n 
= e^{\lambda t} \sum_{n=0}^\infty \frac{1}{n!} (tN)^n 
= e^{\lambda t}
\begin{pmatrix}
1 & t & \frac{t^2}{2!} & \cdots & \frac{t^{r-1}}{(r-1)!} \\
& 1 & t & \ddots & \vdots \\
& & \ddots & \ddots & \frac{t^2}{2!} \\
& & & 1 & t \\
& & & & 1
\end{pmatrix}
$$

wobei  

$$
N := 
\begin{pmatrix}
0 & 1 & & \\
& 0 & \ddots & \\
& & \ddots & 1 \\
& & & 0
\end{pmatrix}
$$

---

## Beweis:

$$
J = \lambda I + N \quad \text{mit} \quad N = 
\begin{pmatrix}
0 & 1 & & \\
& 0 & \ddots & \\
& & \ddots & 1 \\
& & & 0
\end{pmatrix}
\in \mathbb{R}^{r \times r}
$$

---

Beobachtung:

$$
N^2 = 
\begin{pmatrix}
0 & 0 & 1 & & \\
& 0 & 0 & \ddots & \\
& & \ddots & \ddots & 1 \\
& & & 0 & 0 \\
& & & & 0
\end{pmatrix},
\quad
N^3 = 
\begin{pmatrix}
0 & 0 & 0 & 1 & \cdots \\
& 0 & 0 & 0 & \ddots \\
& & \ddots & \ddots & \ddots \\
& & & 0 & 0 \\
& & & & 0
\end{pmatrix}
$$

Allgemein gilt:  
$$
N^r = 0 \quad \text{(Nullmatrix)}, \quad \text{da: } N \text{ ist nilpotent.}
$$
## Exponential von Jordanblock $J_i$

$$
e^{tJ_i} = e^{t \lambda_i I + tN} = e^{t \lambda_i I} \cdot e^{tN}
= e^{t \lambda_i} \cdot \sum_{n=0}^{\infty} \frac{1}{n!} (tN)^n
$$

Da $N^r = 0$ (für $N \in \mathbb{R}^{r \times r}$ nilpotent), ergibt sich:

$$
e^{tJ_i} = e^{t \lambda_i} \sum_{n=0}^{r-1} \frac{t^n}{n!} N^n
$$

= ausgewertete Form ✅

---

## 3.3 Inhomogene Systeme

Allgemeine Form:

$$
y' = A(t) y + b(t)
$$

Beobachtung:  
Lösungsraum ist affin: Falls $y_p$ eine Partikularlösung ist, dann ist jede Lösung $y$ von der Form:  
$$
y = y_p + \tilde{y}
$$  
wobei $\tilde{y}$ Lösung des homogenen Systems  
$$
\tilde{y}' = A(t) \tilde{y}
$$  
ist.

---

Ziel:  
Finde eine Partikularlösung $y_p$

Technik:  
„Methode der Variation der Konstanten“
Sei $Y \in C^1(J, \mathbb{R}^{n \times n})$ Fundamentalmatrix für $y' = A(t)y$.

---

Ansatz für partikuläre Lösung:

$$
y_p(t) = Y(t) c(t)
$$

Ableitung:

$$
y_p'(t) = A(t) Y(t) c(t) + Y(t) c'(t)
$$

also:

$$
y_p' = A Y c + Y c' = A (Y c) + b
$$

$\Rightarrow c'(t) = Y(t)^{-1} b(t)$  
(Denn $Y$ ist Fundamentalmatrix, also invertierbar)

---

$\Rightarrow$ Für beliebiges $t_0 \in J$ kann man schreiben:

$$
c(t) = \int_{t_0}^t Y(s)^{-1} b(s)\,ds
$$

und somit:

$$
y_p(t) = Y(t) \int_{t_0}^t Y(s)^{-1} b(s)\,ds
$$

---

## Satz 3.17

Voraussetzung: Keine

Behauptung:

(i) Für jedes $t_0 \in J$ ist  
$$
y_p(t) := Y(t) \int_{t_0}^t Y(s)^{-1} b(s)\, ds
$$  
eine Partikularlösung von  
$$
y' = A(t)y + b(t)
$$

(ii)  
$$
y(t) = Y(t) Y(t_0)^{-1} y_0 + Y(t) \int_{t_0}^t Y(s)^{-1} b(s)\, ds
$$  
ist die Lösung des Anfangswertproblems  
$$
y' = A(t)y + b(t), \quad y(t_0) = y_0
$$

---

Beweis: Ohne Beweis
## Spezialfall:

$$
y' = A y + b(t), \quad A \in \mathbb{R}^{n \times n}
$$

Lösung:

$$
y(t) = e^{tA} y_0 + \int_{t_0}^t e^{(t - s)A} b(s)\, ds
$$

auch schreibbar als:

$$
y(t) = e^{(t - t_0)A} y_0 + \int_{t_0}^t e^{(t - s)A} b(s)\, ds
$$

---

## 3.4 Lineare, skalare ODEs $n$-ter Ordnung

### Homogene Gleichung:

(3.8)  
$$
y^{(n)} + \sum_{j=0}^{n-1} a_j(t) y^{(j)} = 0, \quad t \in J
$$

### Inhomogene Gleichung:

(3.9)  
$$
y^{(n)} + \sum_{j=0}^{n-1} a_j(t) y^{(j)} = b(t), \quad t \in J
$$

---

## Umformung in ein System 1. Ordnung:

Einführung neuer Variablen:

$$
y_1 = y \\
y_2 = y' \\
y_3 = y'' \\
\vdots \\
y_n = y^{(n-1)}
$$

Dann wird Gleichung (3.9) zu einem System erster Ordnung:

(3.10)  
$$
\vec{y}' = A(t) \vec{y} + \vec{b}(t)
$$

mit:

$$
A(t) = \begin{pmatrix}
0 & 1 & 0 & \cdots & 0 \\
0 & 0 & 1 & \cdots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
0 & 0 & 0 & \cdots & 1 \\
-a_0(t) & -a_1(t) & -a_2(t) & \cdots & -a_{n-1}(t)
\end{pmatrix}
\quad \text{(Begleitmatrix)}
$$
Wir können die Techniken und Resultate für Systeme verwenden. Wir haben:

---

(i) Superpositionsprinzip:  
Die Lösungen von (3.8) bilden einen Vektorraum,  
die Lösungen von (3.9) einen affinen Raum.  
Durch Vorgabe von  
$$
J(t),\quad y^{(j)}(t_0),\quad j = 0, \dotsc, (n-1)
$$  
ist die Lösung von (3.8)/(3.9) eindeutig festgelegt.

---

(ii) Jede Lösung von (3.9) hat die Form  
$$
y = y_p + y_h
$$  
mit partikulärer Lösung $y_p$ und einer Lösung $y_h$ von (3.8)

---

(iii) Die Wronski-Determinante von $n$ Lösungen $y^1, \dotsc, y^n$ ist

$$
w(t) = \det
\begin{pmatrix}
y^1 & y^2 & \dots & y^n \\
(y^1)' & (y^2)' & \dots & (y^n)' \\
\vdots & \vdots & \ddots & \vdots \\
(y^1)^{(n-1)} & (y^2)^{(n-1)} & \dots & (y^n)^{(n-1)}
\end{pmatrix}
$$

Es gilt:

- Satz von Liouville:
  $$
  w(t) = w(t_0) \cdot \exp\left( -\int_{t_0}^t a_{n-1}(s)\, ds \right)
  $$

- Die Funktionen $y^1, \dotsc, y^n$ sind linear unabhängig auf $J \iff w(t) \neq 0$ für alle $t \in J$

---

(iv) Man kann so auch Lösungen liefern für Fundamentallösungen

---

(v) Alternativer Reduktionsansatz:  
Falls $y_1$ eine Lösung von (3.8) ist, dann liefert sie …
Ansatz:  
$y = \Phi(t) c(t)$ sei eine ODE der Ordnung $n$ für $y'$

---

### (vi) Variation der Konstanten für Partikulärlösung

Ziel: Eine Partikularlösung für inhomogene lineare DGL $n$-ter Ordnung.

Betrachte den Fall $n = 2$.  
Seien $y^1, y^2 \in C^2$ eine Fundamentallösung (FS) für (3.8).

Ansatz:

$$
y(t) = y^1(t) c_1(t) + y^2(t) c_2(t)
$$

bzw. in Vektorform:

$$
Y(t) c(t), \quad Y(t) = \begin{pmatrix} y^1 & y^2 \end{pmatrix}
$$

Ableitung:

$$
y' = Y' c + Y c'
$$

Gleichung lautet: $y' = A y + b$

$\Rightarrow$ Forderung für Partikulärlösung:

$$
Y' c + Y c' = A Y c + b
$$

$\Rightarrow$  
Multipliziere links mit $Y^{-1}$:

$$
c'(t) = Y(t)^{-1} (b(t))
$$

$\Rightarrow$  
Lösung:

$$
c(t) = \int_{t_0}^t Y(s)^{-1} b(s)\, ds
$$

---

### Beispiel:

$$
y'' + \frac{1}{t+1} y' = 1
$$

Ziel: Partikulärlösung

1. Schritt: Finde FS, d.h. löse homogene Gleichung  
$$
y'' + \frac{1}{t+1} y' = 0
$$

2. Lösung: $y_1 \equiv 1$

3. Lösung: Ansatz $y_2 = z$, wobei $z' + \frac{z}{t+1} = 0$

(Separierbar!):

$$
-\frac{dz}{z} = \frac{dt}{t+1} \Rightarrow \ln|z| = -\ln(t+1) + C \Rightarrow z = \frac{C}{t+1}
$$

Also:  
$$
y_2 = \frac{1}{t+1}
$$
Gegeben:  
$$
z = \frac{C}{t+1}
\Rightarrow y_2 = \ln(1 + t)
$$

---

1. Lösung:  
$$
y_1 = 1, \quad y_2 = \ln(1 + t)
$$  
(linear unabhängig)

Wronski-Determinante:

$$
w(t) = \det
\begin{pmatrix}
y_1 & y_2 \\
y_1' & y_2'
\end{pmatrix}
=
\det \begin{pmatrix}
1 & \ln(1 + t) \\
0 & \frac{1}{1 + t}
\end{pmatrix}
= \frac{1}{1 + t}
$$

---

## 2. Schritt: Ansatz für Partikulärlösung

Ansatz:  
$$
y_p = Y(t) c(t), \quad Y(t) = \begin{pmatrix} 1 & \ln(1 + t) \\ 0 & \frac{1}{1 + t} \end{pmatrix}
$$

$$
y_p' = Y' c + Y c' = A Y c + b
$$

Einsetzen:

$$
Y(t) c'(t) = \begin{pmatrix} 1 & \ln(1 + t) \\ 0 & \frac{1}{1 + t} \end{pmatrix}
\begin{pmatrix} c_1'(t) \\ c_2'(t) \end{pmatrix}
= \begin{pmatrix} 0 \\ 1 \end{pmatrix}
$$

$\Rightarrow$ Gleichungssystem:

- $c_1' + c_2' \ln(1 + t) = 0$  
- $\frac{c_2'}{1 + t} = 1 \Rightarrow c_2' = 1 + t$

Integration:

$$
c_2(t) = t + \frac{1}{2} t^2 \\
c_1' = -c_2' \ln(1 + t) = - (1 + t) \ln(1 + t)
$$

$$
c_1 = - \int (1 + t) \ln(1 + t)\, dt = -\frac{1}{2} (1 + t)^2 \left( \frac{1}{2} - \ln(1 + t) \right)
$$

---

### Partikulärlösung:

$$
y_p(t) = c_1(t) \cdot 1 + c_2(t) \cdot \ln(1 + t) \\
= -\frac{1}{2}(1 + t)^2 \left( \frac{1}{2} - \ln(1 + t) \right)
+ \left( t + \frac{1}{2} t^2 \right) \ln(1 + t)
$$
Allg. Lösung:

$$
y = y_p + a_1 \cdot 1 + a_2 \cdot \ln(1 + t), \quad a_1, a_2 \in \mathbb{R}
$$

---

Bemerkung:  
Für beliebige Funktionen $y^1, \dotsc, y^n \in C^n(I)$ gilt:

$$
W(t) = \det
\begin{pmatrix}
y^1 & \cdots & y^n \\
(y^1)' & \cdots & (y^n)' \\
\vdots & \ddots & \vdots \\
(y^1)^{(n-1)} & \cdots & (y^n)^{(n-1)}
\end{pmatrix}
= 0
$$

$\Rightarrow$ Die Funktionen $y^1, \dotsc, y^n$ sind linear abhängig.

---

Beispiel (für $n = 2$):

$$
y^1(t) = t^4, \quad y^2(t) = 1 + t^3, \quad J \subseteq \mathbb{R}
$$

Sind $y^1, y^2$ linear abhängig?

Untersuche:  
Gibt es $\alpha, \beta \in \mathbb{R}$ mit $\alpha y^1 + \beta y^2 = 0$?

Setze:  
$$
\alpha t^4 + \beta(1 + t^3) = 0 \Rightarrow \alpha = \beta = 0
$$

$\Rightarrow$ linear unabhängig

---

Wronski-Determinante:

$$
W(t) = \det
\begin{pmatrix}
y^1 & y^2 \\
(y^1)' & (y^2)'
\end{pmatrix}
= \det
\begin{pmatrix}
t^4 & 1 + t^3 \\
4t^3 & 4t^2
\end{pmatrix}
$$

$$
= t^4 \cdot 4t^2 - 4t^3 (1 + t^3) = 4t^6 - 4t^3 - 4t^6 = -4t^3
$$

---

## 3.5 Gleichungen mit konstanten Koeffizienten

### Homogene Form:

(3.13)  
$$
y^{(n)} + \sum_{j=0}^{n-1} a_j y^{(j)} = 0
$$

### Inhomogene Form:

(3.14)  
$$
y^{(n)} + \sum_{j=0}^{n-1} a_j y^{(j)} = b(t)
$$

mit $a_0, \dotsc, a_{n-1} \in \mathbb{R}$
Beispiel:  
Der Ansatz  
$$
y(t) = e^{\lambda t}
$$  
in (3.13) liefert:

$$
\frac{d^n}{dt^n} e^{\lambda t} + \sum_{j=0}^{n-1} a_j \frac{d^j}{dt^j} e^{\lambda t} = 0
$$

Ableitung:

$$
\lambda^n e^{\lambda t} + \sum_{j=0}^{n-1} a_j \lambda^j e^{\lambda t} = 0
$$

Faktorisieren:

$$
\left( \lambda^n + \sum_{j=0}^{n-1} a_j \lambda^j \right) e^{\lambda t} = 0
$$

$\Rightarrow$ $e^{\lambda t}$ ist Lösung von (3.13)  
$\iff$ $\lambda$ ist eine Nullstelle des charakteristischen Polynoms

---

Polynom:

$$
\chi(\lambda) := \lambda^n + \sum_{j=0}^{n-1} a_j \lambda^j
$$
