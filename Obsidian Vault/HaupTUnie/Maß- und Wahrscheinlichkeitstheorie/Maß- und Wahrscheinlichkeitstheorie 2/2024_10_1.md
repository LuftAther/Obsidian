# Wiederholung zu  Maß- und Wahrscheinlichkeitstheorie 1

-  Definition 1.1. Das Mengensystem $\mathcal{A}$ heißt
# Convergence of sequences of measurable functions/random variables

Wir wissen was es bedeutet wen eine folge $(x_{n})_{n} \in \mathbb{R} \text{ oder } \mathbb{R}^n$ gegen einen wert $x$ konvergiert. 
In Maß- und Wahrscheinlichkeitstheorie gibt es ähnliche Konzepte für die Konvergenz von Messbaren Funktionen (und Zufalsvariablen).

Wir betrachten folgende Formen.
1. Konvergiert fast sicher
2. Konvergenz Im Maß
3. Konvergenz in $\mathcal{L}¹$
4. Konvergenz in $\mathcal{L}^p$
5. Konvergenz in Verteilung

Die Konvergenzen sind nicht gleichwertig. vgl. Das Schwache Gesetz  der großen Zahlen.
In dem man eine Konvergenz der art:

$\lim_{N \to \infty} \mathbb{P}\left( \left| \frac{\sum_{k \leq 1} X_k}{N} - \mathbb{E}X_{1} \right| > \epsilon \right) = 0.$ 
hat.

Und im vergleich das Starke gesetzt der großen Zahlen. Haben wir eine Konvergenz der Form:

$\mathbb{P}(\lim_{N \to \infty} \frac{\sum_{k \leq 1} X_k}{N} = \mathbb{E} X_{1}) = 1$

In beiden Fällen hat man die Aussage das $\frac{\sum_{i \leq N}X_{i}}{N}$ gegen $\mathbb{E}X_{1}$ geht.
### Definitioin 1.1 :

Die intuitivste Definition der Konvergenz einer Folge von Funktionen $(f_n)_{n > 1}$ gegen eine Funktion $f$, wobei $f, f_n: \Omega \to \mathbb{R}$, ist die punktweise Konvergenz: 
Für jedes $(\omega \in \Omega)$ konvergiert $f_n(\omega)$ für $n \to \infty$  zu $f(\omega)$. Da Mengen von Maß Null oft vernachlässigt werden kann, kommen wir zu der Definition der fast überall Konvergenz. In vielen Fällen konvergieren Folgen $(f_n)_{n > 1}$ jedoch im Großteil des Raums nahe an  $f$, aber nicht fast überall. Daher werden weitere Konvergenzbegriffe eingeführt, wie Konvergenz im Maß, in $\mathcal{L}^1$, $\mathcal{L}^p$, usw.

1. ==Konvergiert fast sicher:==
Sei $f, f_1, f_2, \dots$ eine Folge messbarer Funktionen von $(\Omega, \mathcal{A})$ nach $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$. 
Wir sagen, dass $f_n$ fast überall (a.s.) gegen $f$  konvergiert, falls eine Menge $N \in \mathcal{A}$ mit  $\mu(N) = 0$ existiert, so dass für jedes $\omega \in \Omega \setminus N$ gilt: $f_n(\omega) \to f(\omega) \quad \text{für } n \to \infty.$  Wir schreiben dann $f_n \xrightarrow{\text{a.s.}} f$ 

2. ==Konvergenz Im Maß:==
Wir sagen, dass $f_n$ im Maß (stochastisch) gegen $f$ konvergiert, und schreiben $f_n \xrightarrow{\text{stoch}} f$, wenn für jedes $A \in \mathcal{A}$ mit $\mu(A) < \infty$ und für jedes $\epsilon > 0$ gilt:  $\lim_{n \to \infty} \mu\left(\{ \omega \in A : |f_n(\omega) - f(\omega)| > \epsilon \} \right) = 0$.

3. ==Konvergenz in $\mathcal{L}¹$: ==
 Wir sagen, dass $f_n$ im Maß (stochastisch) gegen $f$ konvergiert, und schreiben $f_n \xrightarrow{\text{stoch}} f$, wenn für jedes $A \in \mathcal{A}$ mit $\mu(A) < \infty$ und für jedes $\epsilon > 0$ gilt:  $\lim_{n \to \infty} \mu\left(\{ \omega \in A : |f_n(\omega) - f(\omega)| > \epsilon \} \right) = 0.$ 

- Wenn darüber hinaus $f, f_1, f_2, \dots \in L^1(\mu)$, dann sagen wir, dass $f_n$ in $L^1(\mu)$ konvergiert (konvergiert in Mittel) gegen $f$, und schreiben $f_n \xrightarrow{L^1} f$, wenn $\|f_n - f\|_1 := \int |f_n - f| \, d\mu \to 0 \quad \text{für } n \to \infty$

### Bemerkung 1.2:

Wenn $\mathbb{P}$ ein Wahrscheinlichkeitsmaß ist und $f_n$ eine Zufallsvariable, dann sagen wir, dass $f_n$ in der Wahrscheinlichkeit gegen $f$ konvergiert, anstelle von $f_n$ konvergiert im Maß gegen $f$. 
Ebenso sagen wir, dass $f_n$ fast sicher gegen $f$ konvergiert, anstelle von $f_n$ konvergiert fast überall gegen $f$. 
Die Folge $f_n$ konvergiert fast überall gegen $f$, wenn es eine Menge $N \in \mathcal{A}$ mit $\mu(N) = 0$ gibt, so dass für jedes $\omega \in \Omega \setminus N$ gilt: $$ f_n(\omega) \to f(\omega) \quad \text{für } n \to \infty. $$ Falls $\mu(\Omega) < \infty$ ist (z. B. bei einem Wahrscheinlichkeitsmaß), können wir die Menge $A$ weglassen, sodass die Bedingung vereinfacht: $$ \lim_{n \to \infty} \mu\left(\{ |f_n - f| > \epsilon \} \right) = 0 \quad \text{für jedes } \epsilon > 0. $$
## Bemerkung 1.3:

Gegeben eine Folge messbarer Funktionen $(f_n)_{n>1}$ ist die Menge $N$, auf der die Folge nicht konvergiert, notwendigerweise messbar. Tatsächlich konvergiert $(f_n(\omega))$ für ein festes $\omega \in \Omega$  genau dann nicht, wenn sie keine Cauchy-Folge ist. Das bedeutet, dass es ein $k\in \mathbb{N}$ gibt, sodass für alle $p \in \mathbb{N}$ jeweils $m,n>p$ existieren, für die $|f_n(\omega) - f_m(\omega)| > \frac{1}{k}$ gilt. Daraus ergibt sich:

$N = \bigcup_{k \in \mathbb{N}} \bigcap_{p \in \mathbb{N}} \bigcup_{n,m > p} \left\{ \omega : |f_n(\omega) - f_m(\omega)| > \frac{1}{k} \right\}$

Da $f_n$ und $f_m$​ messbar sind, ist auch deren Differenz messbar, ebenso wie der Betrag einer messbaren Funktion (weil die Funktion $x \mapsto |x|$. stetig ist). Daher sind die Mengen $\left\{ \omega : |f_n(\omega) - f_m(\omega)| > \frac{1}{k} \right\}$ messbar und somit auch die Menge $N$, da sie durch abzählbare Vereinigung und Schnitt gebildet wird.

### Bemerkung 1.4
#### Konvergenz im Maß $\dots$ Was machen die Mengen $A$ 

Der Grund, warum in der Definition der Konvergenz im Maß die Mengen $A$ mit $\mu(A) < \inftyμ$ verwendet werden (im Fall, dass $\mu(\Omega) = +\infty$, ist folgender: Betrachten wir z.B. den Maßraum $(\mathbb{R}, \mathcal{B}(\mathbb{R})$, wobei $\lambda$ das Lebesgue-Maß ist. 
Nehmen wir die Funktionsfolge $(f_n)$ mit $f_n(x) = 1$, wenn $x \in [n, n+1]$, und $f_n(x) = 0$ sonst. Diese Folge konvergiert fast überall (tatsächlich überall) gegen $0$. Wenn wir jedoch die Konvergenz im Maß durch die Bedingung $\lim_{n \to \infty} \mu(\{ |f_n - f| > \epsilon \}) = 0$ definierten, würde die Konvergenz im Maß hier nicht gelten, da z.B. $\mu(\{ |f_n| > 1/2 \}) = \infty$. [[Definition 1.1]] fängt die Idee ein, dass in jeder endlichen (im Maß) Region von $\Omega$ der Teilbereich, in dem $|f_n - f| > \epsilon$, sehr klein ist.

Einige Bücher definieren die Konvergenz im Maß ohne Schnitt mit $A$ als $\lim_{n \to \infty} \mu(\{ |f_n - f| > \epsilon \}) = 0$ und bezeichnen [[Definition (1.3)]] als **lokale Konvergenz im Maß**.

## 1.3 Implinkationen 
Die eingefürten konvergenzbegriffe sind nicht equivalent. 
Ansonsten hätte es gereicht nur einen Einzuführen

### Proposition 1.5: 

Konvergenz fast überal $\Rightarrow$ Konvergenz im Maß

### Beweis(Proposition 1.5):

Tatsächlich git $\mu(\{ |f_n - f| > \epsilon \} \cap A) \leq \mu(\{ \exists m > n : |f_m - f| > \epsilon \} \cap A)$
Andererseits ist die Menge $( D_n(\epsilon) = \{ \exists m > n : |f_m - f| > \epsilon \} )$ für $(n)$ absteigend, sodass
$\mu(D_n(\epsilon) \cap A) \to \mu(D(\epsilon) \cap A) \text{, wenn } n \to \infty,$ wobei $( D(\epsilon) = \bigcap_{n=1}^{\infty} D_n(\epsilon))$ gilt. Dies folgt aus der Stetigkeit des Maßes $(\mu)$ von oben sowie der Tatsache, dass $( D_n(\epsilon) \cap A )$ endliches Maß hat. Für $(\omega)$, die zur Menge $( D(\epsilon))$ gehören, konvergiert die Folge $( f_n(\omega))$ nicht gegen $( f(\omega))$. Daher ist $( D(\epsilon) \subseteq N )$. Nach der Definition der Konvergenz fast überall gilt $(\mu(D(\epsilon)) = 0)$, sodass auch $(\mu(D(\epsilon) \cap A) = 0)$  ist. Wir schließen daraus, dass $\mu(\{ |f_n - f| > \epsilon \} \cap A) \to 0.$

### Bemerkung 1.6:  
Konvergenz im Maß $\nRightarrow$ Konvergenz Fast überall

Sei $X_i$ für $i > 1$ eine Folge unabhängiger Bernoulli-Zufallsvariablen mit Parameter $\frac{1}{i}$. Das heißt, $P(X_i = 1) = \frac{1}{i}$  ,  $P(X_i = 0) = 1 - \frac{1}{i}$ und die $X_i$ sind unabhängig. Offensichtlich konvergiert $X_i$ in Wahrscheinlichkeit gegen Null: $P(X_i > \epsilon) = P(X_i = 1) = \frac{1}{i}$, was gegen Null konvergiert, wenn $i \to \infty$ . Andererseits, da die Ereignisse $\{ X_i = 1 \}$ unabhängig sind und $\sum_{i} P(X_i = 1) = \sum_{i} \frac{1}{i} = \infty$, folgt aus dem Borel-Cantelli-Lemma, dass für fast jedes $\omega$ gilt, dass $\limsup_{i \to \infty} X_i(\omega) = 1$. Mit anderen Worten, $X_i$ konvergiert nicht fast sicher gegen $0$. Hier ist ein weiteres klassisches Beispiel, das den Unterschied zwischen den verschiedenen Arten der Konvergenz veranschaulicht. In diesem Fall ist unser Maßraum das Intervall $[0, 1]$ mit der Borel-$\sigma$ -Algebra und dem Lebesgue-Maß. Um die Folge $(f_n)$ zu definieren, definieren wir zuerst eine Folge $(I_n)_{n > 1}$ von Intervallen $I_n \subseteq [0, 1]$. Dies geschieht wie folgt: Teile $[0, 1]$ in zwei Intervalle der Länge $\frac{1}{2}$; dies sind die ersten beiden Intervalle $I_1, I_2$ in der Folge. Um die nächsten drei Intervalle $I_3, I_4, I_5$ zu erhalten, teile $[0, 1]$ in drei Intervalle der Länge $\frac{1}{3}$ und so weiter (du siehst das Muster). Definiere dann $f_n$ als die Indikatorfunktion des Intervalls $ I_n $. Es ist klar, dass $(f_n)$ gegen die Funktion $f = 0$ in Maß und auch in $\mathcal{L}^1$ konvergiert. Andererseits ändert sich für jedes $x \in [0, 1]$ der Wert von $f_n(x)$ unendlich oft zwischen den Werten $0$ und $1$ (auch wenn das Auftreten von $1$ immer seltener wird), sodass die Folge punktweise nirgendwo konvergiert.

### Bemerkung 1.7
Stochastische oder Fast-überall-Konvergenz legen den Grenzwert eindeutig fest bis auf Gleichheit fast überall. In der Tat: Sei $f_n \xrightarrow{\text{stoch}} f$ und $f_n \xrightarrow{\text{stoch}} g$. Seien $A_1, A_2, \dots \in \mathcal{A}$ mit $A_n \uparrow \Omega$ und $\mu(A_n) < \infty$ für jedes $n \in \mathbb{N}$. Dann ist (wegen $d(f, g) \leq d(f, f_n) + d(g, f_n)$) für jedes $m \in \mathbb{N}$ und $\epsilon > 0$ $\mu(A_m \cap \{d(f, g) > \epsilon\}) \leq \mu(A_m \cap \{d(f, f_n) > \epsilon/2\}) + \mu(A_m \cap \{d(g, f_n) > \epsilon/2\}) \xrightarrow{n \to \infty} 0$ . Also ist $\mu(\{d(f, g) > 0\}) = 0$.

### Proposition 1.8
Wenn $f_n$ in $L^1$ gegen $f$ konvergiert, dann gilt auch $\int f_n \, d\mu \rightarrow \int f \, d\mu$ und $f_n$ konvergiert gegen $f$ in Maß.

### Beweis(Proposition 1.8)

Um die erste Aussage zu sehen, beachten wir einfach, dass
$$\left| \int f_n \, d\mu - \int f \, d\mu \right| = \left| \int (f_n - f) \, d\mu \right| \leq \int |f_n - f| \, d\mu = \|f - f_n\|_1$$.

Um die zweite Aussage zu beweisen, erinnern wir uns daran, dass $A$ eine messbare Menge endlichen Maßes ist. Angenommen, $\mu(A) > 0$, andernfalls ist es offensichtlich, dass $\mu(\{ |f_n - f| > \epsilon \} \cap A) = 0$ und es gibt nichts zu beweisen. Dann gilt:
$$\mu(\{ |f_n - f| > \epsilon \} \cap A) \leq \mu(\{ |f_n - f| > \epsilon \}) \leq \frac{\|f - f_n\|_1}{\epsilon}$$

Dies folgt einfach daraus, dass für eine positive messbare Funktion $f$ gilt
$$$\|f\|_1 = \int f \, d\mu \geq \int f \cdot \mathbf{1}_{\{f > \epsilon\}} \, d\mu \geq \epsilon \, \mu(\{f > \epsilon\})$$
(dies ist nichts anderes als die Markow-Ungleichung, die wir letztes Jahr gesehen haben). Daher konvergiert $\mu(\{ |f_n - f| > \epsilon \} \cap A)$ gegen Null, wenn $f_n$ gegen $f$ in $L^1(\mu)$ konvergiert.

### Bemerkung 1.9.
Wir haben gerade bewiesen, dass, wenn $f_n$ in $L^1$ gegen $f$ konvergiert, dann auch $\int f_n \, d\mu \rightarrow \int f \, d\mu$. Andererseits gilt die Umkehrung im Allgemeinen nicht (finden Sie ein Gegenbeispiel).

### Bemerkung 1.10.
Im Allgemeinen implizieren fast-überall-Konvergenz und $L^1$-Konvergenz einander nicht. Betrachten Sie zum Beispiel auf $(\mathbb{R}, \mathcal{B}(\mathbb{R}), \mu)$ (mit $\mu$ das Lebesgue-Maß) die Folge von Funktionen $f_n$, definiert durch $f_n(x) = \frac{1}{n}$ für $|x| \leq n^2$ und $f_n(x) = 0$ sonst. Dann konvergiert $f_n$ offensichtlich fast überall gegen $f \equiv 0$ (tatsächlich sogar überall). Andererseits gilt $\|f_n - 0\|_1 = \int f_n \, d\mu = \frac{1}{n} \cdot n^2 = n$, was nicht gegen Null konvergiert, sondern tatsächlich divergiert.

Für ein Gegenbeispiel in die andere Richtung betrachten wir die Folge $X_i$ von Zufallsvariablen aus Bemerkung 1.6. Wir haben $\|X_i\|_1 = \mathbb{E}(X_i) = \frac{1}{i}$, sodass $X_i$ in $L^1$ gegen 0 konvergiert. Dennoch haben wir bereits gesehen, dass $X_i$ nicht fast sicher gegen Null konvergiert.

## 1.4 Beispiele

### Beispiel 1.11.
Sei $X_n$ eine Folge von i.i.d. Bernoulli-Zufallsvariablen mit Parameter $1/2$ und definiere $Y_N = \prod_{i=1}^N (2 X_i)$. Zeige, dass $Y_N$ fast sicher gegen 0 konvergiert für $N \to \infty$, und dass $Y_N$ nicht in $L^1$ gegen 0 konvergiert.

### Beispiel 1.12. (Schwaches und starkes Gesetz der großen Zahlen)
Die Aussage (1.1) des schwachen Gesetzes der großen Zahlen ist äquivalent dazu, dass die Zufallsvariable $S_N = \frac{1}{N} \sum_{i=1}^N X_i$ in Wahrscheinlichkeit (oder in Maß) gegen $\mathbb{E}(X_1)$ konvergiert. Die Aussage (1.2) des starken Gesetzes der großen Zahlen ist äquivalent dazu, dass $S_N$ fast sicher gegen $\mathbb{E}(X_1)$ konvergiert.

### Beispiel 1.13.
Sei $X_n$ eine Folge unabhängiger, exponentialverteilter Zufallsvariablen und sei $X_n \sim \operatorname{Exp}(a_n)$, wobei $(a_n)_{n \geq 1}$ eine Folge positiver Zahlen ist, die gegen unendlich geht. Da $\mathbb{E}(X_n) = \frac{1}{a_n}$, konvergiert dieser Erwartungswert gegen Null. Unter welchen Bedingungen an die Folge $(a_n)_{n \geq 1}$ konvergiert die Folge $(X_n)_{n \geq 1}$ fast sicher gegen Null? Wie steht es um die $L^1$-Konvergenz?

### Lösung(1.13).
Die Frage der $L^1$-Konvergenz ist einfach: $\|X_n\|_1 = \mathbb{E}(X_n) = \frac{1}{a_n}$ konvergiert gegen Null, sodass $X_n$ in $L^1$ gegen 0 konvergiert, ohne weitere Voraussetzungen. Zur fast sicheren Konvergenz gegen Null: Das Ereignis $A_n = \{X_n > \epsilon\}$ hat eine Wahrscheinlichkeit von $e^{-a_n \epsilon}$, da $X_n$ exponentialverteilt ist. Dieses konvergiert gegen Null mit $n$. Falls $\sum_n e^{-a_n \epsilon} < \infty$, dann tritt das Ereignis $A_n$ nur endlich oft auf (fast sicher) nach dem Borel-Cantelli-Lemma. Wenn also $\sum_n e^{-a_n \epsilon} < \infty$ für jedes $\epsilon > 0$, konvergiert $X_n$ fast sicher gegen Null. Andererseits sind die Ereignisse $A_n$ unabhängig, daher gilt nach dem Borel-Cantelli-Lemma: Falls $\sum_n e^{-a_n \epsilon} = \infty$, tritt $A_n$ unendlich oft auf, was bedeutet, dass $X_n$ nicht fast sicher gegen Null konvergiert. Daher haben wir fast sichere Konvergenz gegen Null genau dann, wenn $\sum_n e^{-a_n \epsilon} < \infty$ für jedes $\epsilon > 0$. Zum Beispiel ist dies für $a_n = (\log n)^2$ erfüllt, jedoch nicht für $a_n = \log n$ (ÜBERPRÜFEN!).

### Beispiel 1.14.
In den bisherigen Beispielen erfolgte die Konvergenz stets gegen eine triviale (konstante) Funktion. Dies ist jedoch nur ein Spezialfall. Betrachten wir das folgende Beispiel: Wir haben eine faire Münze und zwei Urnen: Urne A enthält eine schwarze und eine weiße Kugel, Urne B enthält eine schwarze und zwei weiße Kugeln. Wir führen folgendes Experiment durch: Zuerst werfen wir die Münze. Zeigt die Münze Kopf, ziehen wir zufällig eine Kugel aus Urne A (jedes Mal unabhängig und mit Zurücklegen, d.h. wir legen die Kugel zurück, bevor die nächste gezogen wird); zeigt die Münze Zahl, ziehen wir aus Urne B (ebenfalls mit Zurücklegen). Wir bezeichnen mit $X_N$ die Anzahl der schwarzen Kugeln unter den ersten $N$ Ziehungen. Verwenden Sie das Gesetz der großen Zahlen, um zu zeigen, dass $\frac{X_N}{N}$ in Wahrscheinlichkeit und fast sicher gegen einen Grenzwert konvergiert, der mit Wahrscheinlichkeit $1/2$ gleich $1/2$ und mit Wahrscheinlichkeit $1/2$ gleich $1/3$ ist.

Ein weiteres Beispiel ist das folgende: Sei $(X_n)_{n \geq 1}$ eine Folge unabhängiger Bernoulli-Zufallsvariablen mit Parameter $1/2$, also $P(X_n = 1) = P(X_n = 0) = 1/2$. Definiere $Y_N = \sum_{n \leq N} \frac{1}{n^2} X_n$. Da $X_n$ nicht negativ ist, ist $Y_N$ wachsend, sodass es fast sicher gegen einen Grenzwert $Y_\infty$ konvergiert. Dieser Grenzwert ist endlich, da $Y_N \leq \sum_{n=1}^{\infty} \frac{1}{n^2} < \infty$. Überzeugen Sie sich selbst davon, dass $Y_\infty$ eine echte Zufallsvariable ist (d.h., dass sie nicht konstant ist!).
