# Wiederholung zu  Maß- und Wahrscheinlichkeitstheorie 1

-  Definition 1.1. Das Mengensystem $\mathcal{A}$ heißt
## Convergence of sequences of measurable functions/random variables

Wir wissen was es bedeutet wen eine folge $(x_{n})_{n} \in \mathbb{R} \text{ oder } \mathbb{R}^n$ gegen einen wert $x$ konvergiert. 
In Maß- und Wahrscheinlichkeitstheorie gibt es ähnliche Konzepte für die Konvergenz von Messbaren Funktionen (und Zufalsvariablen).

Wir betrachten folgende Formen.
1. Konvergiert fast sicher
2. Konvergenz Im Maß
3. Konvergenz in $\mathcal{L}¹$
4. Konvergenz in $\mathcal{L}^p$
5. Konvergenz in Verteilung

Die Konvergenzen sind nicht gleichwertig. vgl. Das Schwache Gesetz  der großen Zahlen.
In dem man eine Konvergenz der art:

$\lim_{N \to \infty} \mathbb{P}\left( \left| \frac{\sum_{k \leq 1} X_k}{N} - \mathbb{E}X_{1} \right| > \epsilon \right) = 0.$ 
hat.

Und im vergleich das Starke gesetzt der großen Zahlen. Haben wir eine Konvergenz der Form:

$\mathbb{P}(\lim_{N \to \infty} \frac{\sum_{k \leq 1} X_k}{N} = \mathbb{E} X_{1}) = 1$

In beiden Fällen hat man die Aussage das $\frac{\sum_{i \leq N}X_{i}}{N}$ gegen $\mathbb{E}X_{1}$ geht.

## Definitioin 1.1 :

Die intuitivste Definition der Konvergenz einer Folge von Funktionen $(f_n)_{n > 1}$ gegen eine Funktion $f$, wobei $f, f_n: \Omega \to \mathbb{R}$, ist die punktweise Konvergenz: 
Für jedes $(\omega \in \Omega)$ konvergiert $f_n(\omega)$ für $n \to \infty$  zu $f(\omega)$. Da Mengen von Maß Null oft vernachlässigt werden kann, kommen wir zu der Definition der fast überall Konvergenz. In vielen Fällen konvergieren Folgen $(f_n)_{n > 1}$ jedoch im Großteil des Raums nahe an  $f$, aber nicht fast überall. Daher werden weitere Konvergenzbegriffe eingeführt, wie Konvergenz im Maß, in $\mathcal{L}^1$, $\mathcal{L}^p$, usw.

1. ==Konvergiert fast sicher:==
Sei $f, f_1, f_2, \dots$ eine Folge messbarer Funktionen von $(\Omega, \mathcal{A})$ nach $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$. 
Wir sagen, dass $f_n$ fast überall (a.s.) gegen $f$  konvergiert, falls eine Menge $N \in \mathcal{A}$ mit  $\mu(N) = 0$ existiert, so dass für jedes $\omega \in \Omega \setminus N$ gilt: $f_n(\omega) \to f(\omega) \quad \text{für } n \to \infty.$  Wir schreiben dann $f_n \xrightarrow{\text{a.s.}} f$ 

2. ==Konvergenz Im Maß:==
Wir sagen, dass $f_n$ im Maß (stochastisch) gegen $f$ konvergiert, und schreiben $f_n \xrightarrow{\text{stoch}} f$, wenn für jedes $A \in \mathcal{A}$ mit $\mu(A) < \infty$ und für jedes $\epsilon > 0$ gilt:  $\lim_{n \to \infty} \mu\left(\{ \omega \in A : |f_n(\omega) - f(\omega)| > \epsilon \} \right) = 0$.

3. ==Konvergenz in $\mathcal{L}¹$: ==
 Wir sagen, dass $f_n$ im Maß (stochastisch) gegen $f$ konvergiert, und schreiben $f_n \xrightarrow{\text{stoch}} f$, wenn für jedes $A \in \mathcal{A}$ mit $\mu(A) < \infty$ und für jedes $\epsilon > 0$ gilt:  $\lim_{n \to \infty} \mu\left(\{ \omega \in A : |f_n(\omega) - f(\omega)| > \epsilon \} \right) = 0.$ 

- Wenn darüber hinaus $f, f_1, f_2, \dots \in L^1(\mu)$, dann sagen wir, dass $f_n$ in $L^1(\mu)$ konvergiert (konvergiert in Mittel) gegen $f$, und schreiben $f_n \xrightarrow{L^1} f$, wenn $\|f_n - f\|_1 := \int |f_n - f| \, d\mu \to 0 \quad \text{für } n \to \infty$

## Bemerkung 1.2:

Wenn $\mathbb{P}$ ein Wahrscheinlichkeitsmaß ist und $f_n$ eine Zufallsvariable, dann sagen wir, dass $f_n$ in der Wahrscheinlichkeit gegen $f$ konvergiert, anstelle von $f_n$ konvergiert im Maß gegen $f$. 
Ebenso sagen wir, dass $f_n$ fast sicher gegen $f$ konvergiert, anstelle von $f_n$ konvergiert fast überall gegen $f$. 
Die Folge $f_n$ konvergiert fast überall gegen $f$, wenn es eine Menge $N \in \mathcal{A}$ mit $\mu(N) = 0$ gibt, so dass für jedes $\omega \in \Omega \setminus N$ gilt: $$ f_n(\omega) \to f(\omega) \quad \text{für } n \to \infty. $$ Falls $\mu(\Omega) < \infty$ ist (z. B. bei einem Wahrscheinlichkeitsmaß), können wir die Menge $A$ weglassen, sodass die Bedingung vereinfacht: $$ \lim_{n \to \infty} \mu\left(\{ |f_n - f| > \epsilon \} \right) = 0 \quad \text{für jedes } \epsilon > 0. $$