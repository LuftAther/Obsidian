# Wiederholung zu  Maß- und Wahrscheinlichkeitstheorie 1

-  Definition 1.1. Das Mengensystem $\mathcal{A}$ heißt
# Convergence of sequences of measurable functions/random variables

Wir wissen was es bedeutet wen eine folge $(x_{n})_{n} \in \mathbb{R} \text{ oder } \mathbb{R}^n$ gegen einen wert $x$ konvergiert. 
In Maß- und Wahrscheinlichkeitstheorie gibt es ähnliche Konzepte für die Konvergenz von Messbaren Funktionen (und Zufalsvariablen).

Wir betrachten folgende Formen.
1. Konvergiert fast sicher
2. Konvergenz Im Maß
3. Konvergenz in $\mathcal{L}¹$
4. Konvergenz in $\mathcal{L}^p$
5. Konvergenz in Verteilung

Die Konvergenzen sind nicht gleichwertig. vgl. Das Schwache Gesetz  der großen Zahlen.
In dem man eine Konvergenz der art:

$\lim_{N \to \infty} \mathbb{P}\left( \left| \frac{\sum_{k \leq 1} X_k}{N} - \mathbb{E}X_{1} \right| > \epsilon \right) = 0.$ 
hat.

Und im vergleich das Starke gesetzt der großen Zahlen. Haben wir eine Konvergenz der Form:

$\mathbb{P}(\lim_{N \to \infty} \frac{\sum_{k \leq 1} X_k}{N} = \mathbb{E} X_{1}) = 1$

In beiden Fällen hat man die Aussage das $\frac{\sum_{i \leq N}X_{i}}{N}$ gegen $\mathbb{E}X_{1}$ geht.
### Definitioin 1.1 :

Die intuitivste Definition der Konvergenz einer Folge von Funktionen $(f_n)_{n > 1}$ gegen eine Funktion $f$, wobei $f, f_n: \Omega \to \mathbb{R}$, ist die punktweise Konvergenz: 
Für jedes $(\omega \in \Omega)$ konvergiert $f_n(\omega)$ für $n \to \infty$  zu $f(\omega)$. Da Mengen von Maß Null oft vernachlässigt werden kann, kommen wir zu der Definition der fast überall Konvergenz. In vielen Fällen konvergieren Folgen $(f_n)_{n > 1}$ jedoch im Großteil des Raums nahe an  $f$, aber nicht fast überall. Daher werden weitere Konvergenzbegriffe eingeführt, wie Konvergenz im Maß, in $\mathcal{L}^1$, $\mathcal{L}^p$, usw.

1. ==Konvergiert fast sicher:==
Sei $f, f_1, f_2, \dots$ eine Folge messbarer Funktionen von $(\Omega, \mathcal{A})$ nach $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$. 
Wir sagen, dass $f_n$ fast überall (a.s.) gegen $f$  konvergiert, falls eine Menge $N \in \mathcal{A}$ mit  $\mu(N) = 0$ existiert, so dass für jedes $\omega \in \Omega \setminus N$ gilt: $f_n(\omega) \to f(\omega) \quad \text{für } n \to \infty.$  Wir schreiben dann $f_n \xrightarrow{\text{a.s.}} f$ 

2. ==Konvergenz Im Maß:==
Wir sagen, dass $f_n$ im Maß (stochastisch) gegen $f$ konvergiert, und schreiben $f_n \xrightarrow{\text{stoch}} f$, wenn für jedes $A \in \mathcal{A}$ mit $\mu(A) < \infty$ und für jedes $\epsilon > 0$ gilt:  $\lim_{n \to \infty} \mu\left(\{ \omega \in A : |f_n(\omega) - f(\omega)| > \epsilon \} \right) = 0$.

3. ==Konvergenz in $\mathcal{L}¹$: ==
 Wir sagen, dass $f_n$ im Maß (stochastisch) gegen $f$ konvergiert, und schreiben $f_n \xrightarrow{\text{stoch}} f$, wenn für jedes $A \in \mathcal{A}$ mit $\mu(A) < \infty$ und für jedes $\epsilon > 0$ gilt:  $\lim_{n \to \infty} \mu\left(\{ \omega \in A : |f_n(\omega) - f(\omega)| > \epsilon \} \right) = 0.$ 

- Wenn darüber hinaus $f, f_1, f_2, \dots \in L^1(\mu)$, dann sagen wir, dass $f_n$ in $L^1(\mu)$ konvergiert (konvergiert in Mittel) gegen $f$, und schreiben $f_n \xrightarrow{L^1} f$, wenn $\|f_n - f\|_1 := \int |f_n - f| \, d\mu \to 0 \quad \text{für } n \to \infty$

### Bemerkung 1.2:

Wenn $\mathbb{P}$ ein Wahrscheinlichkeitsmaß ist und $f_n$ eine Zufallsvariable, dann sagen wir, dass $f_n$ in der Wahrscheinlichkeit gegen $f$ konvergiert, anstelle von $f_n$ konvergiert im Maß gegen $f$. 
Ebenso sagen wir, dass $f_n$ fast sicher gegen $f$ konvergiert, anstelle von $f_n$ konvergiert fast überall gegen $f$. 
Die Folge $f_n$ konvergiert fast überall gegen $f$, wenn es eine Menge $N \in \mathcal{A}$ mit $\mu(N) = 0$ gibt, so dass für jedes $\omega \in \Omega \setminus N$ gilt: $$ f_n(\omega) \to f(\omega) \quad \text{für } n \to \infty. $$ Falls $\mu(\Omega) < \infty$ ist (z. B. bei einem Wahrscheinlichkeitsmaß), können wir die Menge $A$ weglassen, sodass die Bedingung vereinfacht: $$ \lim_{n \to \infty} \mu\left(\{ |f_n - f| > \epsilon \} \right) = 0 \quad \text{für jedes } \epsilon > 0. $$
## Bemerkung 1.3:

Gegeben eine Folge messbarer Funktionen $(f_n)_{n>1}$ ist die Menge $N$, auf der die Folge nicht konvergiert, notwendigerweise messbar. Tatsächlich konvergiert $(f_n(\omega))$ für ein festes $\omega \in \Omega$  genau dann nicht, wenn sie keine Cauchy-Folge ist. Das bedeutet, dass es ein $k\in \mathbb{N}$ gibt, sodass für alle $p \in \mathbb{N}$ jeweils $m,n>p$ existieren, für die $|f_n(\omega) - f_m(\omega)| > \frac{1}{k}$ gilt. Daraus ergibt sich:

$N = \bigcup_{k \in \mathbb{N}} \bigcap_{p \in \mathbb{N}} \bigcup_{n,m > p} \left\{ \omega : |f_n(\omega) - f_m(\omega)| > \frac{1}{k} \right\}$

Da $f_n$ und $f_m$​ messbar sind, ist auch deren Differenz messbar, ebenso wie der Betrag einer messbaren Funktion (weil die Funktion $x \mapsto |x|$. stetig ist). Daher sind die Mengen $\left\{ \omega : |f_n(\omega) - f_m(\omega)| > \frac{1}{k} \right\}$ messbar und somit auch die Menge $N$, da sie durch abzählbare Vereinigung und Schnitt gebildet wird.

### Bemerkung 1.4
#### Konvergenz im Maß $\dots$ Was machen die Mengen $A$ 

Der Grund, warum in der Definition der Konvergenz im Maß die Mengen $A$ mit $\mu(A) < \inftyμ$ verwendet werden (im Fall, dass $\mu(\Omega) = +\infty$, ist folgender: Betrachten wir z.B. den Maßraum $(\mathbb{R}, \mathcal{B}(\mathbb{R})$, wobei $\lambda$ das Lebesgue-Maß ist. 
Nehmen wir die Funktionsfolge $(f_n)$ mit $f_n(x) = 1$, wenn $x \in [n, n+1]$, und $f_n(x) = 0$ sonst. Diese Folge konvergiert fast überall (tatsächlich überall) gegen $0$. Wenn wir jedoch die Konvergenz im Maß durch die Bedingung $\lim_{n \to \infty} \mu(\{ |f_n - f| > \epsilon \}) = 0$ definierten, würde die Konvergenz im Maß hier nicht gelten, da z.B. $\mu(\{ |f_n| > 1/2 \}) = \infty$. [[Definition 1.1]] fängt die Idee ein, dass in jeder endlichen (im Maß) Region von $\Omega$ der Teilbereich, in dem $|f_n - f| > \epsilon$, sehr klein ist.

Einige Bücher definieren die Konvergenz im Maß ohne Schnitt mit $A$ als $\lim_{n \to \infty} \mu(\{ |f_n - f| > \epsilon \}) = 0$ und bezeichnen [[Definition (1.3)]] als **lokale Konvergenz im Maß**.

## 1.3 Implinkationen 
Die eingefürten konvergenzbegriffe sind nicht equivalent. 
Ansonsten hätte es gereicht nur einen Einzuführen

### Proposition 1.5: 

Konvergenz fast überal $\Rightarrow$ Konvergenz im Maß

### Beweis(Proposition 1.5):

Tatsächlich git $\mu(\{ |f_n - f| > \epsilon \} \cap A) \leq \mu(\{ \exists m > n : |f_m - f| > \epsilon \} \cap A)$
Andererseits ist die Menge $( D_n(\epsilon) = \{ \exists m > n : |f_m - f| > \epsilon \} )$ für $(n)$ absteigend, sodass
$\mu(D_n(\epsilon) \cap A) \to \mu(D(\epsilon) \cap A) \text{, wenn } n \to \infty,$ wobei $( D(\epsilon) = \bigcap_{n=1}^{\infty} D_n(\epsilon))$ gilt. Dies folgt aus der Stetigkeit des Maßes $(\mu)$ von oben sowie der Tatsache, dass $( D_n(\epsilon) \cap A )$ endliches Maß hat. Für $(\omega)$, die zur Menge $( D(\epsilon))$ gehören, konvergiert die Folge $( f_n(\omega))$ nicht gegen $( f(\omega))$. Daher ist $( D(\epsilon) \subseteq N )$. Nach der Definition der Konvergenz fast überall gilt $(\mu(D(\epsilon)) = 0)$, sodass auch $(\mu(D(\epsilon) \cap A) = 0)$  ist. Wir schließen daraus, dass $\mu(\{ |f_n - f| > \epsilon \} \cap A) \to 0.$

### Bemerkung 1.6:  
Konvergenz im Maß $\nRightarrow$ Konvergenz Fast überall

Sei $X_i$ für $i > 1$ eine Folge unabhängiger Bernoulli-Zufallsvariablen mit Parameter $\frac{1}{i}$. Das heißt, $P(X_i = 1) = \frac{1}{i}$  ,  $P(X_i = 0) = 1 - \frac{1}{i}$ und die $X_i$ sind unabhängig. Offensichtlich konvergiert $X_i$ in Wahrscheinlichkeit gegen Null: $P(X_i > \epsilon) = P(X_i = 1) = \frac{1}{i}$, was gegen Null konvergiert, wenn $i \to \infty$ . Andererseits, da die Ereignisse $\{ X_i = 1 \}$ unabhängig sind und $\sum_{i} P(X_i = 1) = \sum_{i} \frac{1}{i} = \infty$, folgt aus dem Borel-Cantelli-Lemma, dass für fast jedes $\omega$ gilt, dass $\limsup_{i \to \infty} X_i(\omega) = 1$. Mit anderen Worten, $X_i$ konvergiert nicht fast sicher gegen $0$. Hier ist ein weiteres klassisches Beispiel, das den Unterschied zwischen den verschiedenen Arten der Konvergenz veranschaulicht. In diesem Fall ist unser Maßraum das Intervall $[0, 1]$ mit der Borel-$\sigma$ -Algebra und dem Lebesgue-Maß. Um die Folge $(f_n)$ zu definieren, definieren wir zuerst eine Folge $(I_n)_{n > 1}$ von Intervallen $I_n \subseteq [0, 1]$. Dies geschieht wie folgt: Teile $[0, 1]$ in zwei Intervalle der Länge $\frac{1}{2}$; dies sind die ersten beiden Intervalle $I_1, I_2$ in der Folge. Um die nächsten drei Intervalle $I_3, I_4, I_5$ zu erhalten, teile $[0, 1]$ in drei Intervalle der Länge $\frac{1}{3}$ und so weiter (du siehst das Muster). Definiere dann $f_n$ als die Indikatorfunktion des Intervalls $ I_n $. Es ist klar, dass $(f_n)$ gegen die Funktion $f = 0$ in Maß und auch in $\mathcal{L}^1$ konvergiert. Andererseits ändert sich für jedes $x \in [0, 1]$ der Wert von $f_n(x)$ unendlich oft zwischen den Werten $0$ und $1$ (auch wenn das Auftreten von $1$ immer seltener wird), sodass die Folge punktweise nirgendwo konvergiert.