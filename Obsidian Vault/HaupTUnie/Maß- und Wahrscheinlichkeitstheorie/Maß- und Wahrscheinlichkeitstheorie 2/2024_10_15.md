\subsection{2.3 Konvergenz in $L^p$}

In Analogie zu Definition 1.1:

### Definition 2.3.

Gegebenen Funktionen $f$ und $(f_n)_{n > 1}$, die zu $L^p(\mu)$ gehören, sagen wir, dass $f_n$ in $L^p$ gegen $f$ konvergiert (und wir schreiben $f_n \xrightarrow{L^p} f$), wenn 

$$
\lim_{n \to \infty} \|f_n - f\|_p = 0.
$$

### Satz 2.4.

Sei $p \in [1, \infty)$ und $(f_n)_{n > 1}$ eine Folge von Funktionen in $L^p(\mu)$. Die folgenden zwei Aussagen sind äquivalent:

1. Es gibt $f \in L^p(\mu)$ mit $f_n \xrightarrow{L^p} f$.

2. $(f_n)_{n > 1}$ ist eine Cauchy-Folge in $L^p(\mu)$, d.h. $\|f_n - f_m\|_p$ konvergiert gegen null, wenn $n, m \to \infty$.

Wenn $p < 1$, sind diese auch äquivalent zu

3. die Folge $(|f_n|^p)_{n > 1}$ ist gleichmäßig integrierbar und $(f_n)_{n > 1}$ konvergiert in Maß zu einer messbaren Funktion $f$, die mit dem $f$ von Punkt 1 übereinstimmt.

Der Beweis (?) ist sehr ähnlich dem von [[Klenke Satz 6.25]]  der für den Fall $p = 1$ gilt, daher lasse ich ihn aus (siehe [Klenke], Seite 164).

\textbf{Bemerkung 2.5.} Wenn wir uns in einem Wahrscheinlichkeitsraum befinden und $X$ eine reellwertige Zufallsvariable ist, dann ist ihre Norm $\| \cdot \|_p$ für $p \in \mathbb{N}$ nichts anderes als das, was wir im letzten Jahr das $\textit{p-te Moment}$ genannt haben.

### 2.2 Ungleichungen

Im letzten Jahr haben wir zwei grundlegende Ungleichungen gesehen: die Markov-/Tschebyscheff-Ungleichung und die Cauchy-Schwarz-Ungleichung. Hier werden wir eine weitere grundlegende Ungleichung beweisen, die Jensen-Ungleichung. Wir werden einige Anwendungen sehen, zum Beispiel die Tatsache, dass $\|\cdot\|_p$ eine Norm auf $L^p$ ist, wenn $p > 1$.

Zunächst wollen wir den wichtigen Begriff der Konvexität wiederholen: die Konvexität einer Menge und die Konvexität einer Funktion, die auf einer konvexen Menge definiert ist.

### Definition 2.6 (Konvexe Menge):

Eine Teilmenge $G$ eines Vektorraums $V$ heißt konvex, wenn $x, y \in G$ und $\lambda \in [0, 1]$ impliziert, dass $\lambda x + (1 - \lambda)y \in G$. Geometrisch bedeutet dies, dass gegeben zwei Punkte $x, y$ in $G$, das gesamte Segment von $x$ nach $y$ zu $G$ gehört. Zum Beispiel ist eine Scheibe eine konvexe Teilmenge von $\mathbb{R}^2$, aber der Buchstabe $U$ ist es nicht.

### Beispiel 2.7:

Ein weniger trivialer Beispiel als die Scheibe ist die Menge $M_1$ aller Wahrscheinlichkeitsmaße auf einem messbaren Raum $(\Omega, \mathcal{A})$.

### Definition 2.8(Konvexe/konkave Funktion):

Gegeben einer konvexen Menge $G$ und einer reellwertigen Funktion $f: G \to \mathbb{R}$ sagen wir, dass $f$ konvex ist, wenn $x, y \in G$ und $\lambda \in [0, 1]$ implizieren, dass 

$$
f(\lambda x + (1 - \lambda)y) \leq \lambda f(x) + (1 - \lambda)f(y).
$$

Wir sagen, dass $f$ konkav ist, wenn $-f$ konvex ist. 

Wenn $G = \mathbb{R}$ und $f$ eine zweimal differenzierbare Funktion ist, ist diese Definition von Konvexität (oder Konkavität) äquivalent zu der üblichen Bedingung, dass $f''(x) > 0$ (oder $f''(x) < 0$).

Ich gehe davon aus, dass Sie mit den grundlegenden Eigenschaften konvexer Funktionen auf $\mathbb{R}$ vertraut sind. Diese sind in [[Klenke Satz 7.7]] von [Klenke] zusammengefasst, den ich hier nicht wiederhole. Insbesondere existieren die links- und rechtsseitigen Ableitungen $D^{-}f$, $D^{+}f$ überall in $I$ und sind monoton steigende Funktionen. Darüber hinaus existiert die Ableitung $f'(x) = D^{-}f(x) = D^{+}f(x)$, außer an einer endlichen oder abzählbaren Menge von Werten von $x$.

Hier ist Jensens Ungleichung:

\textbf{Satz 2.9.} (Jensens Ungleichung) Sei $I$ ein Intervall in $\mathbb{R}$ und $f: I \to \mathbb{R}$ eine konvexe Funktion. Wenn $X$ eine Zufallsvariable mit Werten in $I$ ist und $E(|X|) < \infty$ (d.h. $X$ ist integrierbar), dann gilt:

$$
E(f(X)) \geq f(E(X)). \tag{2.3}
$$

Wenn $f$ stattdessen konkav ist, dann wird die Ungleichung umgekehrt.

\textbf{Beweis.} Zunächst wollen wir sicherstellen, dass $E(f(X))$ wohl definiert ist. Denken Sie daran, dass der schlechte Fall der ist, wenn die Erwartung der positiven und der negativen Teile einer Zufallsvariable $Y$ beide unendlich sind, in welchem Fall wir $E(Y)$ nicht definieren. Im Fall von $f(X)$ zeigen wir, dass $E(f(X)^{-}) < \infty$: Tatsächlich ist eine konvexe Funktion größer als jede gerade Linie, die tangential zu ihr ist, sodass es konstante $a, b$ gibt, sodass 

$$
f(x) > ax + b.
$$ 

Dann gilt $E(f(X)^{-}) \leq |a| E(|X|) + |b| < \infty$. Zusammenfassend: $E(f(X))$ ist wohl definiert, möglicherweise gleich $+\infty$.

Jetzt wollen wir (2.3) beweisen. Beachten Sie, dass nach der Monotonie der Erwartung $E(X) \in I$ ist: Angenommen zunächst, dass $E(X)$ im Inneren von $I$ liegt. Dann nennen wir $t^{+}$ die Ableitung von $f$ an $E(X)$ oder, falls sie dort nicht differenzierbar ist, dann $t^{+} = D^{+}f(E(X))$. Nach der Definition der Konvexität gilt:

$$
f(x) > t^{+}(x - E(X)) + f(E(X)).
$$

Wählen wir $x = X$ und ziehen die Erwartung in Bezug auf $X$, erhalten wir die gewünschte Ungleichung.

Betrachten wir schließlich den Fall, in dem $E(X)$ einer der beiden Randpunkte von $I$ ist (falls es eine Grenze hat). Zum Beispiel, sagen wir, dass $E(X) = a$, wobei $a$ das Infimum von $I$ ist. Da $X \geq a$ nach Annahme gilt, impliziert $E(X)$, dass $X = a$ fast sicher. Dann gilt (2.3) als Gleichheit.
