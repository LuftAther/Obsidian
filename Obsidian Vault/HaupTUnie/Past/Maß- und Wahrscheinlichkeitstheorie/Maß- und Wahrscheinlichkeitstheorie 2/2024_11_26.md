#### Beispiel 4.26:

Sei $(X, Y)$ normalverteilt $N(\mu, \Sigma)$ mit $\mu = (\mu_1, \mu_2) \in \mathbb{R}^2$ und $\Sigma$ eine $2 \times 2$ positiv definite Matrix. Bestimme $\mathbb{E}(X \mid Y)$. 

##### Lösung([[#Beispiel 4.26]]): 

Erinnern wir uns daran, dass die Dichte von $N(\mu, \Sigma)$ bezüglich des Lebesgue-Maßes auf $\mathbb{R}^2$ gegeben ist durch: $$ f(x, y) = \frac{1}{2\pi \sqrt{\det(\Sigma)}} e^{-\frac{1}{2} ((x, y) - \mu)^\top \Sigma^{-1} ((x, y) - \mu)}, $$ wobei $\Sigma^{-1}$ die Inverse von $\Sigma$ und $v^\top$ die Transposition des Spaltenvektors $v$ ist. Erinnern wir uns außerdem aus der linearen Algebra: $$ (\Sigma^{-1})_{11} = \frac{\Sigma_{22}}{\det(\Sigma)}, \quad (\Sigma^{-1})_{22} = \frac{\Sigma_{11}}{\det(\Sigma)}, \quad (\Sigma^{-1})_{12} = -\frac{\Sigma_{12}}{\det(\Sigma)}. $$ Wir erinnern uns außerdem, dass gilt: $$ \mathbb{E}(X_1) = \mu_1, \quad \mathbb{E}(X_2) = \mu_2, \quad \text{Var}(X_1) = \Sigma_{11}, \quad \text{Var}(X_2) = \Sigma_{22}, \quad \text{Cov}(X_1, X_2) = \Sigma_{12}. \tag{4.20}$$ Diese Beziehungen können direkt gezeigt werden, indem die Dichte eingesetzt und die Integrale berechnet werden. Wir bestimmen zuerst die Marginaldichte von $X_2$: $$ f_2(y) = \int_{\mathbb{R}} f(x, y) \, dx $$ $$ f_2(y) = e^{-\frac{1}{2} (y - m_2)^2 \frac{\Sigma_{11}}{\det(\Sigma)}} \frac{1}{2\pi \sqrt{\det(\Sigma)}} \int_{\mathbb{R}} \exp \left[ -\frac{1}{2} \left( \frac{(x - m_1)^2 \Sigma_{22}}{\det(\Sigma)} + \frac{(x - m_1)(y - m_2) \Sigma_{12}}{\det(\Sigma)} \right) \right] dx $$ $$ = e^{-\frac{1}{2} (y - m_2)^2 \frac{\Sigma_{11}}{\det(\Sigma)}} \frac{1}{2\pi \sqrt{\det(\Sigma)}} \int_{\mathbb{R}} \exp \left[ -\frac{1}{2} \frac{x^2 \Sigma_{22}}{\det(\Sigma)} + x (y - m_2) \frac{\Sigma_{12}}{\det(\Sigma)} \right] dx $$ $$ = e^{-\frac{1}{2} (y - m_2)^2 \frac{\Sigma_{11} - \frac{\Sigma_{12}^2}{\Sigma_{22}}}{\det(\Sigma)}} \frac{1}{\sqrt{2\pi \Sigma_{22}}}. $$ $$ f_2(y) = \frac{1}{\sqrt{2\pi \Sigma_{22}}} e^{-\frac{1}{2} \frac{(y - m_2)^2}{\Sigma_{22}}}. $$ Das zeigt, dass die Marginalverteilung von $X_2$ normalverteilt ist: $N(\mu_2, \Sigma_{22})$. Dies überrascht nicht, in Anbetracht der vorherigen Ergebnisse. Analog ergibt sich, dass die Marginalverteilung von $X_1$ $N(\mu_1, \Sigma_{11})$ ist. Nun berechnen wir: $$ \int_{\mathbb{R}} x f(x, y) \, dx$$ $$= e^{-\frac{1}{2} (y - m_2)^2 \frac{\Sigma_{11}}{\det(\Sigma)}} \frac{1}{2\pi \sqrt{\det(\Sigma)}} \int_{\mathbb{R}} x \exp \left[ -\frac{1}{2} \left( \frac{(x - m_1)^2 \Sigma_{22}}{\det(\Sigma)} + \frac{(x - m_1)(y - m_2) \Sigma_{12}}{\det(\Sigma)} \right) \right] dx. $$ $$ = e^{-\frac{1}{2} (y - m_2)^2 \frac{\Sigma_{11}}{\det(\Sigma)}} \frac{1}{2\pi \sqrt{\det(\Sigma)}} \int_{\mathbb{R}} (x + m_1) \exp \left[ -\frac{1}{2} \frac{x^2 \Sigma_{22}}{\det(\Sigma)} + x (y - m_2) \frac{\Sigma_{12}}{\det(\Sigma)} \right] dx. $$ Durch Substitution und Vereinfachung ergibt sich: $$ = e^{-\frac{1}{2} (y - m_2)^2 \frac{\Sigma_{11} - \frac{\Sigma_{12}^2}{\Sigma_{22}}}{\det(\Sigma)}} \frac{1}{\sqrt{2\pi \Sigma_{22}}} \left[ (y - m_2) \frac{\Sigma_{12}}{\Sigma_{22}} + m_1 \right]. $$ Damit: $$ g(y) = \frac{\int_{\mathbb{R}} x f(x, y) \, dx}{f_2(y)} = (y - m_2) \frac{\Sigma_{12}}{\Sigma_{22}} + m_1. $$ Zusammenfassend gilt für ein Paar korrelierter, gemeinsam normalverteilter Zufallsvariablen $(X_1, X_2)$: $$ \mathbb{E}(X_1 \mid X_2) = m_1 + (X_2 - m_2) \frac{\Sigma_{12}}{\Sigma_{22}}.\tag{4.21} $$Erinnern wir uns daran, dass $\Sigma_{12} = \text{Cov}(X_1, X_2)$ und $\Sigma_{22} = \text{Var}(X_2)$ ist. Dies kann umgeschrieben werden zu: $$ \mathbb{E}(X_1 \mid X_2) = \mathbb{E}(X_1) + (X_2 - \mathbb{E}(X_2)) \frac{\text{Cov}(X_1, X_2)}{\text{Var}(X_2)}.\tag{4.22} $$ Diese Formel ist nur für gemeinsam normalverteilte Variablen gültig.

## Fall II: 

Der Zufallsvektor $(X_1, X_2)$ ist \textit{diskret}. Das bedeutet, es gibt zwei endliche oder abzählbare Mengen $I_1$ und $I_2$, sodass gilt: $$ P(X_1 = x_1, X_2 = x_2) = p(x_1, x_2) \quad \text{für alle } x_1 \in I_1, \, x_2 \in I_2, $$ wobei: $$ \sum_{x_1 \in I_1, x_2 \in I_2} p(x_1, x_2) = 1. $$ In diesem Fall lassen sich die Randverteilungen von $X_1$ und $X_2$ leicht bestimmen. Beide sind diskrete Maße, und es gilt: $$ p_1(x_1) := P(X_1 = x_1) = \sum_{x_2 \in I_2} p(x_1, x_2), $$ $$ p_2(x_2) := P(X_2 = x_2) = \sum_{x_1 \in I_1} p(x_1, x_2). \tag{4.23} $$ Gegeben eine messbare Funktion $h: I_1 \to \mathbb{R}$, sodass $h(X_1)$ integrierbar ist, ist das diskrete Analogon der Formel (4.19): $$ \mathbb{E}(h(X_1) \mid X_2) = g(X_2), $$ wobei: $$ g(x_2) = \begin{cases} \sum_{x_1 \in I_1} h(x_1) \frac{p(x_1, x_2)}{p_2(x_2)}, & \text{wenn } p_2(x_2) > 0, \\ 0, & \text{sonst.} \end{cases} \tag{4.24} $$ Der Beweis, dass $g(X_2)$ so definiert tatsächlich die Eigenschaften von $\mathbb{E}(h(X_1) \mid X_2)$ erfüllt, funktioniert genau wie im Fall mit einer Dichte.