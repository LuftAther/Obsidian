### 13.2.1 Bemerkung:

 Erfüllt eine **stetig differenzierbare Funktion** $\eta(\xi)$ die Beziehung
$$
F(\xi, \eta(\xi))^T = 0 \tag{13.5}
$$
mit einer **stetig differenzierbaren Funktion** $F : D \subset \mathbb{R}^2 \rightarrow \mathbb{R}$, so kann man $\eta'(\xi)$ durch sogenanntes ==implizites Differenzieren== berechnen. 
Dazu setzen wir 

- $f_1(\xi) := \xi$,
- $f_2(\xi) := \eta(\xi)$ und 
- $f(\xi) := (f_1(\xi)f_2(\xi))^T \in \mathbb{R}^2$.

Gemäß (13.5) gilt $h(\xi) := F \circ f (\xi) = 0$, womit auch $h'(\xi) = 0$. Aus der Kettenregel schließen wir auf
$$
0 = h'(\xi) = \frac{\partial}{\partial x_1} F(\xi, \eta(\xi))^T \cdot 1 + \frac{\partial}{\partial x_2} F(\xi, \eta(\xi))^T \cdot \eta'(\xi).
$$
Im Fall $\frac{\partial F}{\partial x_2} (\xi, \eta(\xi)) \neq 0$ folgt
$$
\eta'(\xi) = - \frac{\frac{\partial}{\partial x_1} F(\xi, \eta(\xi))^T}{\frac{\partial}{\partial x_2} F(\xi, \eta(\xi))^T}.
$$

#### Beispiel 13.2.2:

Betrachte die Gleichung $F(\xi_1, \xi_2)^T = 0$ wobei
$$
F : 
\begin{cases}
\mathbb{R}^2 \to \mathbb{R}, \\
x = (\xi_1, \xi_2)^T \mapsto \xi_1^2 + \xi_2^2 - 1.
\end{cases}
$$
Ist durch die implizite Gleichung $F(\xi, \eta(\xi))^T = 0$ eine Funktion $\eta(\xi)$ wohldefiniert? 
Nein, denn erfüllt eine Zahl $\eta(\xi)$ die beziehung dann auch $-\eta(\xi)$.

![[HaupTUnie/Past/Analysis/Analysis_3 1/13 Implizite Funktionen und Mannigfaltigkeit/Loklale_Darstellbarkeit.png| center | 200]]

Man sieht jedoch, dass $F(\xi, \eta) = 0$ für $\xi_0 \neq \pm 1$ zumindest **lokal** um $\xi_0$ eine **stetige** und **stetig differenzierbare** Funktion $\eta(.)$ mit $F(\xi, \eta(\xi))^T = 0$ definiert werden kann, wenn man sich nur im Punkt $\xi_0$ auf einen der beiden möglichen Werte $\eta(\xi_0) = \eta_0$ bzw. $\eta(\xi_0) = -\eta_0$ festlegt.

Beachte, dass wegen $\xi_0 \neq \pm 1$ für jedes $\eta_0$ mit $F(\xi_0, \eta_0)^T = 0$ auch $\frac{\partial}{\partial x_2} F(\xi_0, \eta_0)^T \neq 0$. Lokal um $\xi_0$ erhält man die Ableitung der Lösungsfunktion $\eta$ durch ==implizites Differenzieren==:
$$
0 = \frac{d}{d\xi} F(\xi, \eta(\xi))^T = \frac{\partial}{\partial x_1} F(\xi, \eta(\xi))^T \cdot 1 + \frac{\partial}{\partial x_2} F(\xi, \eta(\xi))^T \cdot \eta'(\xi) = 2\xi + 2\eta(\xi) \cdot \eta'(\xi),
$$
wodurch $\eta'(\xi) = -\frac{\xi}{\eta(\xi)}$.

Wie wir eben gesehen haben, ist es nicht klar, ob durch eine implizite Gleichung $F(\xi, \eta(\xi))^T = 0$ tatsächlich eine Funktion definiert ist. Wie man mit Hilfe von [[#Beispiel 13.2.1]] vielleicht erahnen kann, spielt dabei die Bedingung $\frac{\partial}{\partial x_2} F(\xi_0, \eta_0)^T \neq 0$ eine Rolle. Der in diesem Abschnitt bewiesene Satz über implizite Funktionen, Satz 13.2.3([[#13.2.3 Satz (Satz über implizite Funktionen)]]), gibt die exakte und allgemein formulierte Bestätigung dieser Vorahnung.

Die Ausgangssituation beim Satz über implizite Funktionen ist die, dass eine stetig differenzierbare Funktion $F : D \rightarrow \mathbb{R}^m$ auf einer offenen Menge $D \subset \mathbb{R}^{n+m}$ gegeben ist. Der Übersichtlichkeit halber schreiben wir hier die Elemente von $\mathbb{R}^{n+m}$ als $(x, y)$, wobei $x \in \mathbb{R}^n$, $y \in \mathbb{R}^m$.

Für $(x, y) \in D$ betrachten wir $dF(x, y) \in L(\mathbb{R}^{n+m}, \mathbb{R}^m)$ als eine $m \times (n + m)$ Matrix. Nun nehmen wir die ersten $n$ Spalten und fassen sie zur Matrix $dF_1(x, y)$ zusammen. Entsprechend seien $dF_2(x, y)$ die letzten $m$ Spalten. Man hat also
$$
dF(x, y) =
\begin{pmatrix}  \\
\frac{\partial F_1}{\partial x_1}(x, y) & \cdots & \frac{\partial F_1}{\partial x_n}(x, y) & \frac{\partial F_{1}}{\partial x_{n+1}}(x, y) & \cdots & \frac{\partial F_1}{\partial x_{n+m}}(x, y) \\ \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\ \frac{\partial F_m}{\partial x_1}(x, y) & \cdots & \frac{\partial F_m}{\partial x_n}(x, y) & \frac{\partial F_m}{\partial x_{n+1}}(x, y) & \cdots & \frac{\partial F_m}{\partial x_{n+m}}(x, y) \end{pmatrix}\phantom{dF(x, y)} \qquad $$$$\underbrace{\phantom{\begin{matrix} \frac{\partial F_1}{\partial x_1}(x, y) & \cdots & \frac{\partial F_1}{\partial x_n}(x, y) \\ \vdots & \ddots & \vdots \\ \frac{\partial F_m}{\partial x_1}(x, y) & \cdots & \frac{\partial F_m}{\partial x_n}(x, y)  \\
\end{matrix}}}_{= dF_1(x, y)} \\
\quad \underbrace{\phantom{\begin{matrix} \frac{\partial F_1}{\partial x_{n+1}}(x, y) & \cdots & \frac{\partial F_1}{\partial x_{n+m}}(x, y) \\ \vdots & \ddots & \vdots \\ \frac{\partial F_m}{\partial x_{n+1}}(x, y) & \cdots & \frac{\partial F_m}{\partial x_{n+m}}(x, y) \end{matrix}}}_{= dF_2(x, y)}$$

Mit $dF(x, y)$ sind klarerweise auch $dF_1(x, y)$ und $dF_2(x, y)$ stetig in $(x, y)$. Für festes $y$ ist $x \mapsto dF_1(x, y) \in \mathbb{R}^{m \times n}$ die Ableitung der Funktion $x \mapsto F(x, y)$. Entsprechend ist $y \mapsto dF_2(x, y) \in \mathbb{R}^{m \times m}$ die Ableitung der Funktion $y \mapsto F(x, y)$ bei festem $x$.

### 13.2.3 Satz (Satz über implizite Funktionen)

Sei $D \subseteq \mathbb{R}^{n+m}$ offen und $F : D \to \mathbb{R}^m$ stetig differenzierbar. Weiters sei $(a, b) \in D$ mit $F(a, b) = 0$ derart, dass $dF_2(a, b)$ invertierbar ist, also (Fehler ?? i,2)

$$
\det \left( \frac{\partial F_i}{\partial x_{n+j}} (a, b) \right)_{i,j=1}^m \neq 0.
$$

1. Dann existieren offene Kugeln $U = U_\delta(a) \subseteq \mathbb{R}^n$ um $a$ und $V = U_\rho(b) \subseteq \mathbb{R}^m$ um $b$ sowie eine stetige Funktion $g : U \to V$ mit $U \times V \subseteq D$ und

   $$
   F(x, g(x)) = 0 \quad \text{für alle } x \in U \tag{13.6}.
   $$

2. Die Funktion $g$ löst die Gleichung $F(x, y) = 0$ auf $U \times V$ vollständig in dem Sinne, dass für $(x, y) \in U \times V$ die Gleichheit $F(x, y) = 0$ genau dann gilt, wenn $y = g(x)$. Insbesondere haben wir $b = g(a)$.

3. Die Matrix $dF_2(u, v) \in \mathbb{R}^{m \times m}$ ist für alle $(u, v) \in U \times V$ invertierbar, und die Funktion $g$ ist stetig differenzierbar, wobei für alle $x \in U$

   $$
   dg(x) = -dF_2(x, g(x))^{-1} dF_1(x, g(x)).
   $$

### Beweis zu ([[#13.2.3 Satz (Satz über implizite Funktionen)]]):

Wir setzen $B = dF_2(a, b)$ und wählen $\alpha > 0$ derart, dass $U_{\|.\|_\infty, \alpha}(a, b) \subseteq D$. Für $x \in U_{\|.\|_\infty, \alpha}(a) \subseteq \mathbb{R}^n$ sei
$$
\Phi_x : U_{\|.\|_\infty, \alpha}(b) \to \mathbb{R}^m, \quad \Phi_x(y) := y - B^{-1} F(x, y).
$$
Offenbar ist $\Phi_x$ stetig differenzierbar, wobei $d\Phi_x(y) = I - B^{-1} dF_2(x, y)$. Weiters sei

$$
\psi : [0, \alpha) \to \mathbb{R}, \quad \psi(\eta) := \sup_{(x, y) \in K_{\|.\|_\infty, \eta}(a, b)} \| d\Phi_x(y) \|.
$$

Nach dem Resultat am Ende von Abschnitt 10.1 in $[K]$, angewandt auf die konvexe Menge $K_{\|.\|_\infty, \eta}(b)$, gilt für alle $x \in K_{\|.\|_\infty, \eta}(a)$, $y_1, y_2 \in K_{\|.\|_\infty, \eta}(b)$

$$
\|\Phi_x(y_1) - \Phi_x(y_2)\|_\infty \leq \psi(\eta) \|y_1 - y_2\|_\infty. \tag{13.7}
$$

Wegen der Stetigkeit von $(x, y) \mapsto d\Phi_x(y)$ und $d\Phi_a(b) = 0$ gilt

$$
\lim_{\eta \to 0^+} \psi(\eta) = 0. \tag{13.8}
$$

Insbesondere gibt es ein $\rho \in (0, \alpha)$ mit

$$
\psi(\rho) \leq \frac{1}{2}. \tag{13.9}
$$

Infolge gilt $\|d\Phi_x(y)\| = \|I - B^{-1} dF_2(x, y)\| \leq \frac{1}{2}$ für $(x, y) \in K_{\|.\|_\infty, \rho}(a, b)$, womit $B^{-1} dF_2(x, y) = I - (I - B^{-1} dF_2(x, y))$ für solche $(x, y)$ und daher auch $dF_2(x, y)$ invertierbar ist; siehe Beispiel 9.3.6.

Wegen der Stetigkeit von $F$ bei $(a, b)$ existiert ein $\delta \in (0, \rho]$ mit

$$
\|F(x, b)\|_\infty = \|F(x, b) - F(a, b)\|_\infty \leq \frac{\rho}{4\|B^{-1}\|} \quad \text{für alle } x \in U_{\|.\|_\infty, \delta}(a). \tag{13.10}
$$

Wir setzen $U := U_{\|.\|_\infty, \delta}(a)$ und $V := U_{\|.\|_\infty, \rho}(b)$. Man beachte dabei

$$
U \times V \subseteq U_{\|.\|_\infty, \rho}(a) \times U_{\|.\|_\infty, \rho}(b) = U_{\|.\|_\infty, \rho}(a, b) \subseteq D \subseteq \mathbb{R}^{n+m}. \tag{13.11}
$$

Für eine Funktion $h : U \to \mathbb{R}^m$ derart, dass $h(x) \in V$ für alle $x \in U$, können wir wegen (13.11) auch die Funktion $T(h) : U \to \mathbb{R}^m$ durch

$$
T(h)(x) := h(x) - B^{-1} F(x, h(x)) \quad \text{für } x \in U \tag{13.12}
$$

definieren. Eine Funktion $g : U \to V \subseteq \mathbb{R}^m$ erfüllt genau dann $F(x, g(x)) = 0$ für alle $x \in U$, wenn $T(g) = g$. Diese Fixpunktgleichung wollen wir mit Hilfe des Fixpunktsatzes von Banach, Satz 13.1.1, behandeln.

Dazu betrachten wir den Banachraum $C_b(U, \mathbb{R}^m)$ versehen mit der Supremumsnorm $\|f\| := \sup_{x \in U} \|f(x)\|_\infty$ und darin die abgeschlossene Kugel $K_{\rho/2}(h_0) := M$ um das Element $h_0 \in C_b(U, \mathbb{R}^m)$, wobei $h_0 : U \to \mathbb{R}^m$ die konstante Funktion $x \mapsto b$ ist. Als abgeschlossene Teilmenge eines vollständig metrischen Raumes ist $M$, versehen mit $d(h_1, h_2) := \|h_1 - h_2\|$, ein vollständig metrischer Raum.

Für $h \in M$ und $x \in U$ gilt wegen $|h(x) - b| \leq \|h - h_0\| \leq \frac{\rho}{2} < \rho$ immer $h(x) \in V$, womit $T(h) : U \to \mathbb{R}^m$ durch (13.12) wohldefiniert und offenbar auch stetig ist. Wegen $U \subseteq K_\rho(a)$ und $V \subseteq K_\rho(b)$ erhalten wir aus (13.7) und (13.9) für $h_1, h_2 \in M$

$$
\|T(h_1)(x) - T(h_2)(x)\|_\infty = \|\Phi_x(h_1(x)) - \Phi_x(h_2(x))\|_\infty \leq \frac{1}{2} \|h_1(x) - h_2(x)\|_\infty. \tag{13.13}
$$

1. Für alle $x \in U$ ergibt sich zusammen mit (13.10) die Abschätzung $\|T(h)(x) - h_0(x)\|_{\infty} \leq \|T(h)(x) - T(h_0)(x)\|_{\infty} + \|T(h_0)(x) - h_0(x)\|_{\infty} \leq \frac{\rho}{4} + \|B^{-1}F(x, b)\|_{\infty} \leq \frac{\rho}{2}$ Infolge ist $T(h)$ beschränkt und es gilt $\|T(h) - h_0\| \leq \frac{\rho}{2}$, also $T(h) \in K_{\rho/2}(h_0) = M$. Zudem bedingt (13.13) die Ungleichung $\|T(h_1) - T(h_2)\| \leq \frac{1}{2} \|h_1 - h_2\|$, wodurch sich $T$ als strikte Kontraktion von $M$ nach $M$ herausstellt. Nach dem Banachschen Fixpunktsatz (Satz 13.1.1) gibt es eine eindeutige Funktion $g \in M$, also ein stetiges $g : U \rightarrow K_{\rho/2}(b) \subseteq V \subseteq \mathbb{R}^m$, mit $T(g) = g$ und infolge $F(x, g(x)) = 0$ für alle $x \in U$, wodurch wir (i) gezeigt haben. 2. Für $(x, y) \in U \times V$ mit $F(x, y) = 0$ folgt $\Phi_x(y) = y - B^{-1}F(x, y) = y$. Wegen $F(x, g(x)) = 0$ gilt auch $\Phi_x(g(x)) = g(x)$. Aus (13.7) und (13.9) erhalten wir $$ \|g(x) - y\|_{\infty} = \|\Phi_x(g(x)) - \Phi_x(y)\|_{\infty} \leq \frac{1}{2}\|g(x) - y\|_{\infty}, $$ also $g(x) = y$. Insbesondere gilt $g(a) = b$, womit (ii) nachgewiesen ist. 3. Für (iii) weisen wir zunächst nach, dass $g$ bei $a$ differenzierbar ist, wobei $$ dg(a) = -dF_2(a, b)^{-1} dF_1(a, b). \tag{13.14} $$ 
Für $\|z\|_{\infty} < \delta$ gilt wegen $F(a, g(a)) = F(a + z, g(a + z)) = 0$ 
$g(a + z) - g(a) =$
$(g(a + z) - B^{-1}F(a + z, g(a + z))) - (g(a) - B^{-1}F(a + z, g(a))) - B^{-1}(F(a + z, g(a)) - F(a, g(a)))$  $$ = \Phi_{a+z}(g(a + z)) - \Phi_{a+z}(g(a)) - B^{-1}(dF_1(a, g(a))z + \|z\|_{\infty} \epsilon_1(z)), $$ mit einer Funktion $\epsilon_1 : (U \setminus \{a\}) - a \rightarrow \mathbb{R}^m$ derart, dass $\lim_{z \to 0} \epsilon_1(z) = 0$. Hier wurde verwendet, dass $F$ in der ersten Variablen bei $(a, b)$ differenzierbar ist; siehe (10.5). Weiter ist für $\|z\|_{\infty} < \delta$ ($\leq \rho$) wegen $g(a + z) \in V = U^{\|\cdot\|_{\infty}}_{\rho}(g(a))$ der Ausdruck $$ \eta_z := \max(\|z\|_{\infty}, \|g(a + z) - g(a)\|_{\infty}) $$ kleiner als $\rho$ und konvergiert für $z \to 0$ gegen Null. Mit (13.7) erhalten wir aus (13.15) $$ \|g(a + z) - g(a)\|_{\infty} \leq \psi(\eta_z) \|g(a + z) - g(a)\|_{\infty} + \|B^{-1}\|(\|dF_1(a, g(a))\| + \|\epsilon_1(z)\|_{\infty})\|z\|_{\infty}, $$ bzw. $$ \|g(a + z) - g(a)\|_{\infty} \leq \frac{\|B^{-1}\|(\|dF_1(a, g(a))\| + \|\epsilon_1(z)\|_{\infty})}{1 - \psi(\eta_z)} \|z\|_{\infty}. $$ 4. Addieren wir zu (13.15) den Ausdruck $B^{-1}dF_1(a, b)z$, so folgt $$ g(a + z) - g(a) + B^{-1}dF_1(a, b)z = \Phi_{a+z}(g(a + z)) - \Phi_{a+z}(g(a)) - \|z\|_{\infty} B^{-1} \epsilon_1(z). $$ Für $\epsilon(z) := \frac{1}{\|z\|_{\infty}}(\Phi_{a+z}(g(a + z)) - \Phi_{a+z}(g(a))) - B^{-1} \epsilon_1(z)$ gilt wieder wegen (13.7) $$ \|\epsilon(z)\|_{\infty} \leq \frac{\psi(\eta_z)}{\|z\|_{\infty}} \|g(a + z) - g(a)\|_{\infty} + \|B^{-1}\| \|\epsilon_1(z)\|_{\infty} $$ $$ \leq \frac{\psi(\eta_z)\|B^{-1}\|(\|dF_1(a, g(a))\| + \|\epsilon_1(z)\|_{\infty})}{1 - \psi(\eta_z)} + \|B^{-1}\| \|\epsilon_1(z)\|_{\infty}. $$ Da für $z \rightarrow 0$ wegen (13.8) der Ausdruck rechts gegen Null strebt, erhalten wir die Differenzierbarkeit von $g$ bei $a$ mit der Ableitung $$ dg(a) = -B^{-1}dF_1(a, b) = dF_2(a, b)^{-1} dF_1(a, b). $$ 5. Für $a' \in U$ und $b' = g(a')$ wissen wir aus (i), dass $dF_2(a', b')$ invertierbar ist. Also können wir das schon Bewiesene auf $(a', b') \in U \times V$ anwenden und erhalten eine Kugel $U' \subseteq U$ um $a'$ und eine Kugel $V' \subseteq V$ um $b'$, sowie eine Funktion $g' : U' \rightarrow V'$ mit $g'(a') = b'$ und $F(x, g'(x)) = 0$ für alle $x \in U'$. 6. Nach (ii) erhalten wir $g'(x) = g(x)$ für alle $x \in U'$, und gemäß (13.14) gilt $$ dg(a') = dg'(a') = -dF_2(a', g(a'))^{-1} dF_1(a', g(a')). $$ Die rechte Seite ist nach Korollar 9.3.7 aber stetig in $a'$. Also ist $g$ stetig differenzierbar und die Ableitung lässt sich wie behauptet berechnen
$\square$.

---

### Beispiel 13.2.4:

Wir betrachten die Funktion $F : \mathbb{R}^3 \rightarrow \mathbb{R}$, welche definiert ist durch
$$
F(\zeta_1, \zeta_2, \zeta_3)^T := c_1\zeta_1^2 + c_2\zeta_2^2 + c_3\zeta_3^2 - 1,
$$
wobei $c_1, c_2, c_3 > 0$ vorgegeben sind, und untersuchen die Lösungen der Gleichung $F(\zeta_1, \zeta_2, \zeta_3)^T = 0$. Die Nullstellenmenge $M := \{z \in \mathbb{R}^3 : F(z) = 0\}$ von $F$ bildet in diesem Beispiel ein **Ellipsoid**.

Sei $\alpha = (\alpha_1, \alpha_2, \alpha_3)^T$ eine Lösung von $F(z) = 0$. Wir wollen $F(\zeta_1, \zeta_2, \zeta_3)^T = 0$ lokal bei $\alpha$ nach $\zeta_3$ auflösen. Anders ausgedrückt, fragen wir, ob man die durch die implizite Gleichung $F(z) = 0$ gegebene Fläche $M$ lokal um den Punkt $\alpha$, welcher auf ihr liegt, explizit in der Form $\zeta_3 = g(\zeta_1, \zeta_2)^T$ darstellen kann.

Da $F$ ein Polynom in drei Variablen ist, gilt $F \in C^1$. Die entscheidende ==Funktionaldeterminante== ist die Determinante der $1 \times 1$-Matrix $\left( \frac{\partial F}{\partial \zeta_3} (\alpha) \right)$, wobei
$$
\frac{\partial F}{\partial \zeta_3} (\alpha) = 2c_3 \alpha_3.
$$

Liegt der Punkt $\alpha$ nicht am ==Äquator des Ellipsoids==, gilt also $\alpha_3 \neq 0$, so existiert eine offene **Umgebung** $U \subset \mathbb{R}^2$ von $(\alpha_1, \alpha_2)^T$ und eine $C^1$-Funktion $g : U \rightarrow \mathbb{R}$ mit $g(\alpha_1, \alpha_2)^T = \alpha_3$ und $F(\zeta_1, \zeta_2, g(\zeta_1, \zeta_2)^T)^T = 0$ für alle $(\zeta_1, \zeta_2)^T \in U$. Liegt $\alpha$ dagegen am Äquator, so können wir den Satz über implizite Funktionen ***nicht** anwenden. Tatsächlich ist in solchen Punkten ein Auflösen nach $\zeta_3$ auch ***nicht*** möglich.

![[HaupTUnie/Past/Analysis/Analysis_3 1/13 Implizite Funktionen und Mannigfaltigkeit/Teil_von_M.png|250]]
In unserem Beispiel kann man für jeden Punkt $\alpha \in M$ lokal nach zumindest einer Variablen $\zeta_1$, $\zeta_2$ oder $\zeta_3$ auflösen. In der Tat ist einer der Werte $\alpha_1$, $\alpha_2$, $\alpha_3$ sicher nicht Null. Löst man etwa nach $\zeta_2$ auf, so erhält man eine Funktion $\hat{g}$ mit $F(\zeta_1, \hat{g}(\zeta_1, \zeta_3)^T, \zeta_3)^T = 0$ für $(\zeta_1, \zeta_3)$ lokal um $(\alpha_1, \alpha_3)$.

Man kann das gesamte Ellipsoid $M$ durch die sechs Teilstücke obere Hälfte, untere Hälfte, rechte/linke/vordere/hintere Hälfte beschreiben. Auf diesen Teilstücken hat man
$$
g(\zeta_1, \zeta_2)^T = \pm \sqrt{1 - a \zeta_1^2 - b \zeta_2^2}, \quad \hat{g}(\zeta_1, \zeta_3)^T = \pm \sqrt{1 - a \zeta_1^2 - c \zeta_3^2}, \quad \tilde{g}(\zeta_2, \zeta_3)^T = \pm \sqrt{1 - b \zeta_2^2 - c \zeta_3^2}.
$$
Wir werden später mit Hilfe von Satz 13.5.4 erkennen, dass M eine sogenannte Mannig-
faltigkeit der Dimension 2 im Dreiraum ist. Dieser Begriff der Mannigfaltigkeit ist der
eleganteste und zielführendste, um mit Objekten ähnlich unserem Ellipsoid zu arbeiten.
